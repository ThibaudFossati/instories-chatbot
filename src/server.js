import dotenv from "dotenv";
import rateLimit from 'express-rate-limit';
import express from 'express';
import cors from 'cors';
import fetch from 'node-fetch';

dotenv.config();

const app = express();

// ğŸ” Middlewares
app.use(cors());
app.use(express.json());

// ğŸ›¡ï¸ Limitation des requÃªtes (anti-abus)
const limiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15 minutes
  max: 100, // max 100 requÃªtes / IP
  message: 'ğŸš« Trop de requÃªtes â€“ veuillez patienter un instant.'
});
app.use(limiter);

// ğŸ” API principale
app.post('/api/chat', async (req, res) => {
  const userMessage = req.body.message;

  try {
    const reply = await getBotResponse(userMessage);
    res.json({ reply });
  } catch (error) {
    console.error('Erreur API:', error);
    res.status(500).json({ reply: 'âŒ Erreur serveur' });
  }
});

// ğŸ§  Fonction assistant
async function getBotResponse(message) {
  const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': 'Bearer ' + OPENAI_API_KEY,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      model: 'gpt-4',
      messages: [{ role: 'user', content: message }]
    })
  });

  const data = await response.json();
  return data.choices?.[0]?.message?.content || 'Pas de rÃ©ponse.';
}

// ğŸ”Š Lancement du serveur
const PORT = process.env.PORT || 3001;
app.listen(PORT, () => {
  console.log('âœ… Server running at http://localhost:' + PORT);
});

// ğŸ“‹ Profils crÃ©atifs (Ã  utiliser dans assistant ou pour des suggestions)
const profils = {
  'Directeur Artistique': ['StratÃ©gie visuelle', 'Moodboard', 'Direction de shooting'],
  'Social Media Manager': ['Calendrier Ã©ditorial', 'IdÃ©es de formats', 'TonalitÃ© des posts'],
};
